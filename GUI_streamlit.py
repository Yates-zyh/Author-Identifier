"""
ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å¯åŠ¨æœ¬åœ° Web åº”ç”¨ç¨‹åºï¼š
streamlit run GUI_streamlit.py
å¯åŠ¨ Streamlit åï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­è®¿é—®ï¼šhttp://127.0.0.1:8501
"""
import streamlit as st
from identify import AuthorIdentifier
from generate_with_chatbot import AuthorStyleAPI, chat_with_deepseek, compare_style
import os
import dotenv
import logging
import json

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("streamlit_app")

# åŠ è½½ç¯å¢ƒå˜é‡
dotenv.load_dotenv()

def author_style_analysis(tab):
    """æ–‡æœ¬ä½œè€…é£æ ¼åˆ†æåŠŸèƒ½"""
    # é¡µé¢æ ‡é¢˜
    tab.title("Author Style Identifier")
    tab.markdown("This tool can analyze text and identify potential author styles.")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­æ˜¯å¦å­˜åœ¨ IDENTIFICATION_TOKEN
    token_from_env = os.environ.get("IDENTIFICATION_TOKEN")
    
    # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ tokenï¼Œæ˜¾ç¤º token è¾“å…¥æ¡†
    if not token_from_env:
        tab.warning("No Hugging Face token found in environment variables. The model will be loaded from public repository.")
        tab.info("Optional: You can provide your Hugging Face token for better model access.")
        
        # Token è¾“å…¥æ¡†
        user_token = tab.text_input(
            "Enter your Hugging Face token (optional):",
            type="password",
            help="Your token will be used for this session only and won't be stored.",
            key="id_token"
        )
    else:
        user_token = None  # å¦‚æœç¯å¢ƒå˜é‡ä¸­æœ‰ tokenï¼Œåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ token
        tab.success("Hugging Face token found in environment variables.")
    
    # æ–‡æœ¬è¾“å…¥åŒºåŸŸ
    col1, col2 = tab.columns([3, 1])
    with col1:
        text_input = st.text_area(
            "Enter text to analyze:", 
            height=200, 
            help="Paste the text you want to analyze here."
        )
    
    with col2:
        # é«˜çº§è®¾ç½®
        st.subheader("Analysis Settings")
        confidence_threshold = st.slider(
            "Confidence Threshold", 
            min_value=0.0, 
            max_value=1.0, 
            value=0.6, 
            step=0.05,
            help="Minimum confidence required for identification. Values below this will be marked as 'Unknown Author'."
        )
        
        # æ·»åŠ æ–‡ä»¶ä¸Šä¼ é€‰é¡¹
        st.subheader("Or Upload Text File")
        uploaded_file = st.file_uploader("Choose a file", type=["txt", "md", "html"], key="id_file")
    
    # åˆ†ææŒ‰é’®
    analyze_button = tab.button("Analyze Text", type="primary", use_container_width=True, key="id_analyze")
    
    # ç»“æœå®¹å™¨
    result_container = tab.container()
    
    # å¤„ç†ä¸Šä¼ çš„æ–‡ä»¶
    if uploaded_file is not None and not text_input:
        text_input = uploaded_file.getvalue().decode("utf-8")
        
    # åˆ†æé€»è¾‘
    if analyze_button:
        if not text_input.strip():
            tab.error("Please enter text to analyze or upload a file!")
        else:
            # æ˜¾ç¤ºå¤„ç†çŠ¶æ€
            with st.spinner("Initializing model..."):
                # æ ¹æ®æ˜¯å¦æœ‰ç”¨æˆ·æä¾›çš„ token åˆå§‹åŒ– identifier
                token_to_use = user_token if user_token else token_from_env
                identifier = AuthorIdentifier(token=token_to_use)
                
                # è·å–æ¨¡å‹ä¿¡æ¯å¹¶å­˜å‚¨åˆ°ä¼šè¯çŠ¶æ€
                model_info = identifier.get_model_info()
                st.session_state.model_info = model_info
            
            with st.spinner("Analyzing..."):
                # åˆ†ææ–‡æœ¬
                result = identifier.analyze_text(
                    text_input, 
                    confidence_threshold=confidence_threshold
                )
            
            # æ˜¾ç¤ºç»“æœ
            with result_container:
                tab.subheader("Analysis Results:")
                
                # æ˜¾ç¤ºä¸»è¦ç»“æœ
                col1, col2, col3 = tab.columns(3)
                
                with col1:
                    author = result['predicted_author']
                    tab.info(f"**Predicted Author**: {author}")
                with col2:
                    tab.info(f"**Confidence**: {result['confidence']:.2f}")
                with col3:
                    if 'num_chunks_analyzed' in result:
                        tab.info(f"**Text Chunks Analyzed**: {result['num_chunks_analyzed']}")
                
                # å¦‚æœæœ‰å¤šä¸ªå—ï¼Œæ˜¾ç¤ºä½œè€…åˆ†å¸ƒ
                if 'author_distribution' in result and len(result['author_distribution']) > 1:
                    tab.subheader("Author Distribution in Text Chunks:")
                    
                    # å°†åˆ†å¸ƒæ•°æ®è½¬æ¢ä¸ºè¡¨æ ¼æ ¼å¼
                    dist_data = {"Author": [], "Chunks": [], "Percentage": []}
                    total_chunks = result['num_chunks_analyzed']
                    
                    for author, count in result['author_distribution'].items():
                        dist_data["Author"].append(author)
                        dist_data["Chunks"].append(count)
                        dist_data["Percentage"].append(f"{count/total_chunks*100:.1f}%")
                    
                    tab.dataframe(dist_data)
                
                # æ˜¾ç¤ºæ‰€æœ‰åˆ†ç±»æ¦‚ç‡
                tab.subheader("All Category Probabilities:")
                
                # æŒ‰æ¦‚ç‡ä»é«˜åˆ°ä½æ’åº
                sorted_probs = sorted(result['probabilities'].items(), key=lambda x: x[1], reverse=True)
                
                # åˆ›å»ºè¡¨æ ¼ä»¥æ˜¾ç¤ºæ‰€æœ‰æ¦‚ç‡
                prob_data = {"Author": [], "Probability": []}
                for author, prob in sorted_probs:
                    prob_data["Author"].append(author)
                    prob_data["Probability"].append(f"{prob:.4f}")
                
                tab.dataframe(prob_data)
                
                # æ˜¾ç¤ºæ¨¡å‹æ¥æºä¿¡æ¯
                tab.subheader("Model Information:")
                tab.info(f"Model Path: {model_info.get('model_path', 'Unknown')}")
                tab.info(f"Mode: {model_info.get('mode', 'Unknown')}")
                tab.info(f"Device: {model_info.get('device', 'Unknown')}")

def text_generation(tab):
    """æ–‡æœ¬ç”ŸæˆåŠŸèƒ½ï¼Œåˆ†ä¸ºä¸‰ä¸ªå­é¡µé¢"""
    # é¡µé¢æ ‡é¢˜
    tab.title("Author Style Generator")
    tab.markdown("Generate text in the style of different authors using various models.")
    
    # åˆ›å»ºä¸‰ä¸ªå­æ ‡ç­¾é¡µ
    gen_tab1, gen_tab2, gen_tab3 = tab.tabs([
        "Local Model Generation", 
        "DeepSeek Generation",
        "Style Comparison"
    ])
    
    # è°ƒç”¨å„å­é¡µé¢çš„åŠŸèƒ½
    with gen_tab1:
        local_model_generation(gen_tab1)
    
    with gen_tab2:
        deepseek_generation(gen_tab2)
    
    with gen_tab3:
        style_comparison(gen_tab3)

def local_model_generation(tab):
    """ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆæ–‡æœ¬åŠŸèƒ½"""
    tab.subheader("Generate Text with Local Model")
    tab.markdown("Generate text in the style of different authors using our own fine-tuned language models.")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­æ˜¯å¦å­˜åœ¨ GENERATION_TOKEN
    token_from_env = os.environ.get("GENERATION_TOKEN")
    
    # å¦‚æœç¯å¢ƒå˜é‡ä¸­æ²¡æœ‰ tokenï¼Œæ˜¾ç¤º token è¾“å…¥æ¡†
    if not token_from_env:
        tab.warning("No Hugging Face token found in environment variables. The model will be loaded from public repository.")
        tab.info("Optional: You can provide your Hugging Face token for better model access.")
        
        # Token è¾“å…¥æ¡†
        user_token = tab.text_input(
            "Enter your Hugging Face token (optional):",
            type="password",
            help="Your token will be used for this session only and won't be stored.",
            key="local_gen_token"
        )
    else:
        user_token = None  # å¦‚æœç¯å¢ƒå˜é‡ä¸­æœ‰ tokenï¼Œåˆ™ä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„ token
        tab.success("Hugging Face token found in environment variables.")
    
    # åˆå§‹åŒ– token
    token_to_use = user_token if user_token else token_from_env
    
    # ä½œè€…é€‰æ‹©å’Œè¾“å…¥åŒºåŸŸ
    col1, col2 = tab.columns([3, 1])
    
    # æ‰€æœ‰å¯ç”¨ä½œè€…
    available_authors = [
        "Agatha_Christie",
        "Alexandre_Dumas",
        "Arthur_Conan_Doyle",
        "Charles_Dickens",
        "Charlotte_BrontÃ«",
        "F._Scott_Fitzgerald",
        "GarcÃ­a_MÃ¡rquez",
        "Herman_Melville",
        "Jane_Austen",
        "Mark_Twain"
    ]
    
    with col1:
        # æç¤ºè¾“å…¥åŒºåŸŸ
        prompt_input = tab.text_area(
            "Enter prompt for text generation (optional):", 
            height=150, 
            help="Enter a prompt to start the generated text. Leave empty for open-ended generation."
        )
    
    with col2:
        # é€‰æ‹©ä½œè€…
        selected_author = tab.selectbox(
            "Select Author Style:",
            available_authors,
            help="Choose the author whose style you want to generate text in.",
            key="local_author"
        )
        
        # ç”Ÿæˆè®¾ç½®
        tab.subheader("Generation Settings")
        
        num_samples = tab.slider(
            "Number of Samples", 
            min_value=1, 
            max_value=3, 
            value=1, 
            step=1,
            help="Number of different text samples to generate.",
            key="local_samples"
        )
        
        max_length = tab.slider(
            "Maximum Length", 
            min_value=50, 
            max_value=500, 
            value=200, 
            step=50,
            help="Maximum length of the generated text.",
            key="local_length"
        )
    
    # ç”ŸæˆæŒ‰é’®
    generate_button = tab.button(
        "Generate Text", 
        type="primary", 
        use_container_width=True,
        key="local_generate_btn"
    )
    
    # ç»“æœå®¹å™¨
    result_container = tab.container()
    
    # ä½¿ç”¨æœ¬åœ°æ¨¡å‹ç”Ÿæˆæ–‡æœ¬
    if generate_button:
        with result_container:
            with st.spinner(f"Generating text in the style of {selected_author}..."):
                try:
                    # åˆå§‹åŒ– API å¹¶ç”Ÿæˆæ–‡æœ¬
                    api = AuthorStyleAPI(token=token_to_use)
                    
                    # å°†ç”Ÿæˆçš„æ–‡æœ¬å’Œä½œè€…ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ä¸­ï¼Œä»¥ä¾¿åœ¨æ¯”è¾ƒé¡µé¢ä½¿ç”¨
                    samples = api.generate_text(
                        selected_author,
                        prompt=prompt_input,
                        num_samples=num_samples,
                        max_length=max_length
                    )
                    
                    # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                    if 'local_generated_text' not in st.session_state:
                        st.session_state.local_generated_text = {}
                    
                    st.session_state.local_generated_text = {
                        'author': selected_author,
                        'prompt': prompt_input,
                        'samples': samples
                    }
                    
                    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡æœ¬
                    tab.subheader(f"Generated Text in the Style of {selected_author}")
                    
                    for i, sample in enumerate(samples):
                        tab.markdown(f"**Sample {i+1}:**")
                        tab.markdown(f"```\n{sample}\n```")
                        tab.markdown("---")
                except Exception as e:
                    tab.error(f"Error generating text: {str(e)}")

def deepseek_generation(tab):
    """ä½¿ç”¨ DeepSeek ç”Ÿæˆæ–‡æœ¬åŠŸèƒ½"""
    tab.subheader("Generate Text with DeepSeek API")
    tab.markdown("Generate text in the style of different authors using DeepSeek's powerful language model.")
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡ä¸­æ˜¯å¦å­˜åœ¨ OPENAI_API_KEY
    deepseek_api_key = os.environ.get("OPENAI_API_KEY")
    
    # API å¯†é’¥å¤„ç†
    if not deepseek_api_key:
        tab.warning("No DeepSeek API key found in environment variables.")
        tab.info("Please provide your DeepSeek API key to enable text generation.")
        
        # DeepSeek API å¯†é’¥è¾“å…¥
        user_api_key = tab.text_input(
            "Enter DeepSeek API Key:",
            type="password",
            help="Your DeepSeek API key will be used for this session only.",
            key="deepseek_key_input"
        )
        
        if not user_api_key:
            tab.error("DeepSeek API key is required for text generation.")
            deepseek_enabled = False
        else:
            deepseek_api_key = user_api_key
            deepseek_enabled = True
            tab.success("DeepSeek API key provided successfully.")
    else:
        deepseek_enabled = True
        tab.success("DeepSeek API key found in environment variables.")
    
    # ä½œè€…é€‰æ‹©å’Œè¾“å…¥åŒºåŸŸ
    col1, col2 = tab.columns([3, 1])
    
    # æ‰€æœ‰å¯ç”¨ä½œè€…
    available_authors = [
        "Agatha_Christie",
        "Alexandre_Dumas",
        "Arthur_Conan_Doyle",
        "Charles_Dickens",
        "Charlotte_BrontÃ«",
        "F._Scott_Fitzgerald",
        "GarcÃ­a_MÃ¡rquez",
        "Herman_Melville",
        "Jane_Austen",
        "Mark_Twain"
    ]
    
    with col1:
        # æç¤ºè¾“å…¥åŒºåŸŸ
        prompt_input = tab.text_area(
            "Enter prompt for text generation (optional):", 
            height=150, 
            help="Enter a prompt to start the generated text. Leave empty for open-ended generation.",
            key="deepseek_prompt_input"  # æ·»åŠ å”¯ä¸€çš„key
        )
    
    with col2:
        # é€‰æ‹©ä½œè€…
        selected_author = tab.selectbox(
            "Select Author Style:",
            available_authors,
            help="Choose the author whose style you want to generate text in.",
            key="deepseek_author"
        )
    
    # ç”ŸæˆæŒ‰é’®ï¼ˆæ ¹æ®æ˜¯å¦æœ‰APIå¯†é’¥å†³å®šæ˜¯å¦ç¦ç”¨ï¼‰
    generate_button = tab.button(
        "Generate with DeepSeek", 
        type="primary", 
        use_container_width=True,
        disabled=not deepseek_enabled,
        key="deepseek_generate_btn"
    )
    
    # ç»“æœå®¹å™¨
    result_container = tab.container()
    
    # ä½¿ç”¨ DeepSeek API ç”Ÿæˆæ–‡æœ¬
    if generate_button and deepseek_enabled:
        with result_container:
            with st.spinner(f"Generating text with DeepSeek API in the style of {selected_author}..."):
                try:
                    # ä½¿ç”¨ DeepSeek API ç”Ÿæˆæ–‡æœ¬
                    deepseek_text = chat_with_deepseek(
                        selected_author,
                        prompt=prompt_input,
                        api_key=deepseek_api_key
                    )
                    
                    # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€ï¼Œä»¥ä¾¿åœ¨æ¯”è¾ƒé¡µé¢ä½¿ç”¨
                    if 'deepseek_generated_text' not in st.session_state:
                        st.session_state.deepseek_generated_text = {}
                    
                    st.session_state.deepseek_generated_text = {
                        'author': selected_author,
                        'prompt': prompt_input,
                        'text': deepseek_text
                    }
                    
                    # æ˜¾ç¤ºç”Ÿæˆçš„æ–‡æœ¬
                    tab.subheader(f"DeepSeek Generated Text in the Style of {selected_author}")
                    tab.markdown(f"```\n{deepseek_text}\n```")
                except Exception as e:
                    tab.error(f"Error generating text with DeepSeek: {str(e)}")

def style_comparison(tab):
    """æ¯”è¾ƒä¸¤ç§ç”Ÿæˆæ–¹å¼çš„æ–‡æœ¬é£æ ¼"""
    tab.subheader("Compare Generated Text Styles")
    tab.markdown("Compare text generated by local model and DeepSeek to see which better matches the author's style.")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å·²ç”Ÿæˆçš„æ–‡æœ¬
    has_local_text = 'local_generated_text' in st.session_state and st.session_state.local_generated_text
    has_deepseek_text = 'deepseek_generated_text' in st.session_state and st.session_state.deepseek_generated_text
    
    if not (has_local_text or has_deepseek_text):
        tab.info("Generate text using both Local Model and DeepSeek first to compare their styles.")
        return
    
    # æ˜¾ç¤ºå·²ç”Ÿæˆçš„æ–‡æœ¬
    col1, col2 = tab.columns(2)
    
    with col1:
        tab.subheader("Local Model Generated Text")
        if has_local_text:
            local_data = st.session_state.local_generated_text
            tab.markdown(f"**Author**: {local_data['author']}")
            if local_data['prompt']:
                tab.markdown(f"**Prompt**: {local_data['prompt']}")
            
            # å¦‚æœæœ‰å¤šä¸ªæ ·æœ¬ï¼Œåªæ˜¾ç¤ºç¬¬ä¸€ä¸ªç”¨äºæ¯”è¾ƒ
            if local_data['samples']:
                tab.markdown(f"```\n{local_data['samples'][0]}\n```")
        else:
            tab.info("No text generated with Local Model yet.")
    
    with col2:
        tab.subheader("DeepSeek Generated Text")
        if has_deepseek_text:
            deepseek_data = st.session_state.deepseek_generated_text
            tab.markdown(f"**Author**: {deepseek_data['author']}")
            if deepseek_data['prompt']:
                tab.markdown(f"**Prompt**: {deepseek_data['prompt']}")
            
            tab.markdown(f"```\n{deepseek_data['text']}\n```")
        else:
            tab.info("No text generated with DeepSeek yet.")
    
    # å¦‚æœä¸¤ç§æ–¹å¼éƒ½æœ‰ç”Ÿæˆæ–‡æœ¬ï¼Œå¹¶ä¸”æ˜¯åŒä¸€ä½œè€…ï¼Œåˆ™å¯ä»¥è¿›è¡Œæ¯”è¾ƒ
    if has_local_text and has_deepseek_text:
        local_author = st.session_state.local_generated_text['author']
        deepseek_author = st.session_state.deepseek_generated_text['author']
        
        if local_author == deepseek_author:
            # æ¯”è¾ƒæŒ‰é’®
            compare_button = tab.button(
                "Compare Writing Styles", 
                type="primary", 
                use_container_width=True,
                key="compare_styles_btn"
            )
            
            # è¯„ä¼°ç»“æœå®¹å™¨
            evaluation_container = tab.container()
            
            if compare_button:
                with evaluation_container:
                    with st.spinner("Evaluating text style matching..."):
                        try:
                            token = os.environ.get("GENERATION_TOKEN")
                            
                            # è·å–è¦æ¯”è¾ƒçš„æ–‡æœ¬
                            local_text = st.session_state.local_generated_text['samples'][0]
                            deepseek_text = st.session_state.deepseek_generated_text['text']
                            author = local_author
                            
                            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
                            status_message = st.info("Loading discriminator model...")
                            
                            try:
                                result = compare_style(author, local_text, deepseek_text, token)
                                
                                # æ¸…é™¤çŠ¶æ€æ¶ˆæ¯
                                status_message.empty()
                                
                                # æ˜¾ç¤ºè¯„ä¼°ç»“æœ
                                tab.subheader("Style Matching Evaluation")
                                
                                score_col1, score_col2 = tab.columns(2)
                                with score_col1:
                                    tab.info(f"Local Model Style Match Score: {result['local_score']:.4f}")
                                
                                with score_col2:
                                    tab.info(f"DeepSeek Style Match Score: {result['deepseek_score']:.4f}")
                                
                                # æ¯”è¾ƒç»“æœ
                                tab.subheader("Comparison Result")
                                if result['better_match'] == 'local':
                                    tab.success(f"ğŸ“Š Local Model generated text better matches {author}'s style (score: {result['local_score']:.4f} vs {result['deepseek_score']:.4f}).")
                                elif result['better_match'] == 'deepseek':
                                    tab.success(f"ğŸŒŸ DeepSeek generated text better matches {author}'s style (score: {result['deepseek_score']:.4f} vs {result['local_score']:.4f}).")
                                else:
                                    tab.info("âš–ï¸ Both models generated text with identical style matching scores.")
                                
                                # æ·»åŠ è¯„åˆ†è§£é‡Š
                                tab.markdown("""
                                **Score interpretation**:
                                - Higher scores indicate better style matching with the selected author
                                - Scores range from 0 (not matching) to 1 (perfect match)
                                - Scores above 0.7 typically indicate strong style resemblance
                                """)
                                
                            except Exception as e:
                                # æ¸…é™¤çŠ¶æ€æ¶ˆæ¯å¹¶æ˜¾ç¤ºé”™è¯¯
                                status_message.empty()
                                tab.error(f"Error loading discriminator model: {str(e)}")
                                tab.warning("Unable to use discriminator model. Please try again or check your Hugging Face token.")
                        except Exception as e:
                            tab.error(f"Error comparing text styles: {str(e)}")
        else:
            tab.warning("Cannot compare styles for different authors. Please generate text for the same author with both models.")

def about_page(tab):
    """å…³äºé¡µé¢"""
    # é¡µé¢æ ‡é¢˜
    tab.title("About the Author Style Tool")
    tab.markdown("""
    ### Project Introduction
    
    This application provides a natural language processing tool that analyzes text, identifies potential author styles, and generates text in the style of different authors.
    
    ### Technical Implementation
    
    This project uses:
    - Pre-trained BERT language model for author identification
    - Fine-tuned GPT-2 models for author-style text generation
    - DeepSeek API for advanced text generation capabilities
    - PyTorch deep learning framework
    - Streamlit web interface
    - Hugging Face model hub for model hosting
    
    ### Model Information
    
    The models used in this application:
    - Author identification model: `Yates-zyh/author_identifier`
    - Text generation models: `fjxddy/author-stylegan`
    
    ### Supported Authors
    
    The current version supports the following authors:
    - Agatha Christie
    - Alexandre Dumas
    - Arthur Conan Doyle
    - Charles Dickens
    - Charlotte BrontÃ«
    - F. Scott Fitzgerald
    - GarcÃ­a MÃ¡rquez
    - Herman Melville
    - Jane Austen
    - Mark Twain
    
    ### Usage Instructions
    
    1. **Style Analysis Tab**: Upload text to identify its author style
    2. **Text Generation Tab**: Generate new text in the style of selected authors
    3. **About Tab**: Learn more about the project and available models
    
    ### API Token Configuration
    
    For optimal performance, you can configure the following API tokens in your .env file:
    
    - `IDENTIFICATION_TOKEN`: For accessing Hugging Face author identification models
    - `GENERATION_TOKEN`: For accessing Hugging Face text generation models
    - `OPENAI_API_KEY`: For accessing DeepSeek API (with base URL set to DeepSeek)
    
    If no tokens are configured, the app will attempt to use publicly available models.
    """)
    
    # æ˜¾ç¤ºç¯å¢ƒé…ç½®çŠ¶æ€
    tab.subheader("Environment Configuration Status")
    
    token_status = {
        "IDENTIFICATION_TOKEN": "âœ… Configured" if os.environ.get("IDENTIFICATION_TOKEN") else "âŒ Not configured",
        "GENERATION_TOKEN": "âœ… Configured" if os.environ.get("GENERATION_TOKEN") else "âŒ Not configured",
        "OPENAI_API_KEY": "âœ… Configured" if os.environ.get("OPENAI_API_KEY") else "âŒ Not configured"
    }
    
    tab.dataframe({"Token": list(token_status.keys()), "Status": list(token_status.values())})
    
    # æ˜¾ç¤ºæ›´å¤šæ¨¡å‹ä¿¡æ¯
    if 'model_info' in st.session_state:
        model_info = st.session_state.model_info
        tab.subheader("Detailed Model Information")
        tab.json(model_info)

def main():
    """ä¸»å‡½æ•°ï¼Œåº”ç”¨ç¨‹åºå…¥å£ç‚¹"""
    # è®¾ç½®é¡µé¢æ ‡é¢˜å’Œé…ç½®
    st.set_page_config(page_title="Author Style Tool", layout="wide")
    
    # åˆ›å»ºåŒ…å«åˆ†æå·¥å…·ã€ç”Ÿæˆå·¥å…·å’Œå…³äºä¿¡æ¯çš„æ ‡ç­¾é¡µ
    tab1, tab2, tab3 = st.tabs([
        "Style Analysis", 
        "Text Generation",
        "About"
    ])
    
    # è°ƒç”¨å„æ ‡ç­¾é¡µçš„åŠŸèƒ½
    with tab1:
        author_style_analysis(tab1)
    
    with tab2:
        text_generation(tab2)
    
    with tab3:
        about_page(tab3)

if __name__ == "__main__":
    main()
